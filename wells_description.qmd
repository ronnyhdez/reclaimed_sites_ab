---
title: "Abandoned wells description using polars"
subtitle: "Detailed steps using the exported GeoJSON file"
author: Ronny A. Hernandez Mora
execute:
  message: false
  warning: false
format: 
  html:
    theme:
      - flatly
    linkcolor: "#FF5500"
    highlight-style: tango
    toc: true
    toc-title: Table of contents
    toc-location: left
    number-sections: false
    colorlinks: true
    code-fold: true
    code-line-numbers: true
editor: visual
jupyter: python3
editor_options: 
  chunk_output_type: console
---


This file is using the geojson file exported from GEE on 20250111 to drive
and then locally. Idea is to use polars for getting the tabular data
descriptive statistics and geopandas for using the polygons of each
of the abandoned wells.

The exported data file contains the 1000 filtered polygons and randomly 
selected.


```{python}
import ee
import json
import os
import sys
import glob
import geemap
import pickle
import polars as pl
import seaborn as sns
from pathlib import Path
import pandas as pd
```

```{python}
wells_df = pl.read_json('wells_export.geojson')
buffers_df = pl.read_json('buffers_export.geojson')

# For spatial operations/visualization
# wells_gdf = gpd.read_file('wells_export.geojson')
# buffers_gdf = gpd.read_file('buffers_export.geojson')
```

## Abandoned wells characteristics

First, let's check the structure of the GeoJson file we just
read:

```{python}
wells_df.schema
```

That's kind of a messy printing hard to understand, specially if
it is new data for us that we are not familiared with. What we can
see at first glance is that we have two columns: `type` and `features`

The `type` column is a `string` and the `features` column is a `list`
with a struct and then everything is too coupled together to understand
easily. Let's try to print it in a more understandable way with the `json`
package:

```{python}
single_row = wells_df.head(1)
single_row
```

So, we got the first row (we have just one row in this Polars dataframe)
and the print is telling us the `shape`: 1 row and 2 columns. Basically
what we saw before but less clutered. Then, we have that `features` is
`list[struct[4]]`. This means that we have a list with a struct with
4 fields.

```{python}
features = single_row.get_column('features')
features 
```

Now we have printed just the features column, we can start digging
deeper into its structure. Let's get first the list

```{python}
features[0]
```

The difference is that we can see the first sections of each print:

```{python}
#| eval: false
shape: (1,)
Series: 'features' [list[struct[4]]]

# ---------------

shape: (1_000,)
Series: '' [struct[4]]
```

The first one is telling us that we have a list of features where each
structure has 4 components. The second one shows that within the first row, 
there are 1000 individual features which are represented by a structure of
4 components.

Now let's examine the first feature's properties:

```{python}
first_feature = features[0][0]  
print(json.dumps(first_feature['properties'], indent=2))
```

## From nested structure to data frame 

Now, to continue with operations on flat data, we have to
unnest the dataframe. According to what we saw before with
the structure:


```{python}
wells_flat = wells_df.select(
    pl.col("features").explode()
).select(
    pl.col("features").struct.field("properties").struct.field("*")
)
```

Now we can check the shape of the new object:

```{python}
wells_flat.shape
```


```{python}
buffers_flat = buffers_df.select(
    pl.col("features").explode()
).select(
    pl.col("features").struct.field("properties").struct.field("*")
)
```

```{python}
buffers_flat.glimpse()
```

## Convert dates

The date variables are in miliseconds, so to have a better reading
I'm going to change it to date time.

```{python}
wells_flat = wells_flat.select([
    pl.col("*"),
    pl.from_epoch(
        pl.col("system:time_start"), time_unit="ms"
    ).alias("start_date"),
    pl.from_epoch(
        pl.col("system:time_end"), time_unit="ms"
    ).alias("end_date")
])
```

```{python}
buffers_flat = buffers_flat.select([
    pl.col("*"),
    pl.from_epoch(
        pl.col("system:time_start"), time_unit="ms"
    ).alias("start_date"),
    pl.from_epoch(
        pl.col("system:time_end"), time_unit="ms"
    ).alias("end_date")
])
```

## Remove not useful variables

1 = forest
2 = wetland
3 = crop_herbaceous
4 = other

```{python}
wells_flat.glimpse()
```

```{python}
wells_flat = wells_flat.select(
  pl.all().exclude("olsnd__", "fire_year", "wll_stt",
                   "prd_x__", "^.*intersects.*$", "lcu_id",
                   "rclmtn_s", "system:time_start",
                   "system:time_end", "visible", "source",
                   "intersecting_fires", "fieldnm",
                   "disp_nm", "fetr_ty", "hfi_id", "mn_npr_",
                   "disp_nm", "random", "mx_ls", "rclmtn_c",
                   "mx_ls__", "frst_spd_d", "plygn_s", "area")
)

wells_flat.glimpse()
```

## Rename columns

```{python}
#check = wells_flat.with_columns(
#    area_forest=pl.col("1"),
#    area_wetland=pl.col("2"),
#    area_crop_herbaceous=pl.col("3"),
#    area_other=pl.col("4"),
#    well_site=pl.col("wllst__")
#)

wells_flat = wells_flat.rename({
  "1":"area_forest",
  "2":"area_wetland",
  "3":"area_crop_herbaceous",
  "4":"area_other",
  "wllst__":"well_site",
  "shape_r":"shape_area",
  "nmbr_wl":"number_wells",
  "rclmtn_d":"reclamation_date",
  "mx_bnd_":"max_abandoned_date",
  "shp_lng":"shape_length",
  "frst_spd_y":"first_spud_year"
})
wells_flat.glimpse()
```

```{python}
buffers_flat = buffers_flat.select(
  pl.all().exclude("system:time_start", "system:time_end")
)

buffers_flat = buffers_flat.rename({
  "1":"area_forest",
  "2":"area_wetland",
  "3":"area_crop_herbaceous",
  "4":"area_other"
})

buffers_flat.glimpse()
```
