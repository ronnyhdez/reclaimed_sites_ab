---
title: "Abandoned wells description using polars"
subtitle: "Detailed steps using the exported GeoJSON file"
author: Ronny A. Hernandez Mora
execute:
  message: false
  warning: false
format: 
  html:
    theme:
      - flatly
    linkcolor: "#FF5500"
    highlight-style: tango
    toc: true
    toc-title: Table of contents
    toc-location: left
    number-sections: false
    colorlinks: true
    code-fold: true
    code-line-numbers: true
editor: visual
jupyter: python3
editor_options: 
  chunk_output_type: console
---


This file is using the geojson file exported from GEE on 20250111 to drive
and then locally. Idea is to use polars for getting the tabular data
descriptive statistics and geopandas for using the polygons of each
of the abandoned wells.

The exported data file contains the 1000 filtered polygons and randomly 
selected.


```{python}
import ee
import json
import os
import sys
import glob
import geemap
import pickle
import polars as pl
import seaborn as sns
from pathlib import Path
import pandas as pd
```

```{python}
wells_df = pl.read_json('wells_export.geojson')
buffers_df = pl.read_json('buffers_export.geojson')

# For spatial operations/visualization
# wells_gdf = gpd.read_file('wells_export.geojson')
# buffers_gdf = gpd.read_file('buffers_export.geojson')
```

## Abandoned wells characteristics

First, let's check the structure of the GeoJson file we just
read:

```{python}
wells_df.schema
```

That's kind of a messy printing hard to understand, specially if
it is new data for us that we are not familiared with. What we can
see at first glance is that we have two columns: `type` and `features`

The `type` column is a `string` and the `features` column is a `list`
with a struct and then everything is too coupled together to understand
easily. Let's try to print it in a more understandable way with the `json`
package:

```{python}
single_row = wells_df.head(1)
single_row
```

So, we got the first row (we have just one row in this Polars dataframe)
and the print is telling us the `shape`: 1 row and 2 columns. Basically
what we saw before but less clutered. Then, we have that `features` is
`list[struct[4]]`. This means that we have a list with a struct with
4 fields.

```{python}
features = single_row.get_column('features')
features 
```

Now we have printed just the features column, we can start digging
deeper into its structure. Let's get first the list

```{python}
features[0]
```

The difference is that we can see the first sections of each print:

```{python}
#| eval: false
shape: (1,)
Series: 'features' [list[struct[4]]]

# ---------------

shape: (1_000,)
Series: '' [struct[4]]
```

The first one is telling us that we have a list of features where each
structure has 4 components. The second one shows that within the first row, 
there are 1000 individual features which are represented by a structure of
4 components.

Now let's examine the first feature's properties:

```{python}
first_feature = features[0][0]  
print(json.dumps(first_feature['properties'], indent=2))
```

## From nested structure to data frame 

Now, to continue with operations on flat data, we have to
unnest the dataframe. According to what we saw before with
the structure:


```{python}
wells_flat = wells_df.select(
    pl.col("features").explode()
).select(
    pl.col("features").struct.field("properties").struct.field("*")
)
```

Now we can check the shape of the new object:

```{python}
wells_flat.shape
```


```{python}
buffers_flat = buffers_df.select(
    pl.col("features").explode()
).select(
    pl.col("features").struct.field("properties").struct.field("*")
)
```

```{python}
buffers_flat.glimpse()
```

## Convert dates

The date variables are in miliseconds, so to have a better reading
I'm going to change it to date time.

```{python}
wells_flat = wells_flat.select([
    pl.col("*"),
    pl.from_epoch(
        pl.col("system:time_start"), time_unit="ms"
    ).alias("start_date"),
    pl.from_epoch(
        pl.col("system:time_end"), time_unit="ms"
    ).alias("end_date")
])
```

```{python}
buffers_flat = buffers_flat.select([
    pl.col("*"),
    pl.from_epoch(
        pl.col("system:time_start"), time_unit="ms"
    ).alias("start_date"),
    pl.from_epoch(
        pl.col("system:time_end"), time_unit="ms"
    ).alias("end_date")
])
```

## Remove not useful variables

1 = forest
2 = wetland
3 = crop_herbaceous
4 = other

```{python}
wells_flat.glimpse()
```

```{python}
wells_flat = wells_flat.select(
  pl.all().exclude("olsnd__", "fire_year", "wll_stt",
                   "prd_x__", "^.*intersects.*$", "lcu_id",
                   "rclmtn_s", "system:time_start",
                   "system:time_end", "visible", "source",
                   "intersecting_fires", "fieldnm",
                   "disp_nm", "fetr_ty", "hfi_id", "mn_npr_",
                   "disp_nm", "random", "mx_ls", "rclmtn_c",
                   "mx_ls__", "frst_spd_d", "plygn_s", "area")
)

wells_flat.glimpse()
```

## Rename columns

```{python}
wells_flat = wells_flat.rename({
  "1":"area_forest",
  "2":"area_wetland",
  "3":"area_crop_herbaceous",
  "4":"area_other",
  "wllst__":"well_site",
  "shape_r":"shape_area",
  "nmbr_wl":"number_wells",
  "rclmtn_d":"reclamation_date",
  "mx_bnd_":"max_abandoned_date",
  "shp_lng":"shape_length",
  "frst_spd_y":"first_spud_year"
})
wells_flat.glimpse()
```

```{python}
buffers_flat = buffers_flat.select(
  pl.all().exclude("system:time_start", "system:time_end")
)

buffers_flat = buffers_flat.rename({
  "1":"area_forest",
  "2":"area_wetland",
  "3":"area_crop_herbaceous",
  "4":"area_other",
  "wllst__":"well_site"
})

buffers_flat.glimpse()
```

## Sankey diagram

```{python}
wells_flat.glimpse()
```

```{python}
buffers_flat.glimpse()
```


```{python}
joined_data = wells_flat.join(
    buffers_flat,
    on='well_site'  # same column name in both
)

# Quick verification
print("Original shapes:")
print(f"Wells: {wells_flat.shape}")
print(f"Buffers: {buffers_flat.shape}")
print(f"Joined: {joined_data.shape}")

# Let's look at the first few rows of joined data to verify matching
print("\nFirst few matching pairs:")
print(joined_data.select(['well_site', 'area_forest', 'area_forest_right']).head())
```

```{python}
# First replace nulls with 0 and calculate the actual transitions
land_cover_types = ["area_forest", "area_wetland", "area_crop_herbaceous", "area_other"]

# Get total area for each land cover type in wells and buffers
well_totals = {}
buffer_totals = {}

for lc in land_cover_types:
    well_totals[lc] = joined_data.select(pl.col(lc).fill_null(0)).sum()
    buffer_totals[lc] = joined_data.select(pl.col(f"{lc}_right").fill_null(0)).sum()

print("\nWell totals:", well_totals)
print("\nBuffer totals:", buffer_totals)
```


```{python}
transitions = {
   ('forest', 'forest'): [],
   ('forest', 'wetland'): [],
   ('forest', 'crop'): [],
   ('forest', 'other'): [],
   ('wetland', 'forest'): [],
   ('wetland', 'wetland'): [],
   ('wetland', 'crop'): [],
   ('wetland', 'other'): [],
   ('crop', 'forest'): [],
   ('crop', 'wetland'): [],
   ('crop', 'crop'): [],
   ('crop', 'other'): [],
   ('other', 'forest'): [],
   ('other', 'wetland'): [],
   ('other', 'crop'): [],
    ('other', 'other'): []
} 
# For each row in joined_data:
# If well has forest and buffer has forest -> forest to forest
# If well has forest and buffer has wetland -> forest to wetland
# etc.

print("Let's look at a single well-buffer pair first:")
single_pair = joined_data.select([
    'well_site',
    'area_forest', 'area_wetland', 'area_crop_herbaceous', 'area_other',
    'area_forest_right', 'area_wetland_right', 'area_crop_herbaceous_right', 'area_other_right'
]).head(1)
print(single_pair)
```

```{python}
# Get the data for all wells and buffers
for row in joined_data.iter_rows():
    # Calculate proportions in well
    total_well = sum(x for x in row[1:5] if x is not None)  # Sum of all well areas
    if total_well > 0:
        well_props = [
            (row[1] or 0) / total_well,  # forest
            (row[2] or 0) / total_well,  # wetland
            (row[3] or 0) / total_well,  # crop
            (row[4] or 0) / total_well   # other
        ]
        
        # Calculate proportions in buffer
        total_buffer = sum(x for x in row[5:9] if x is not None)
        if total_buffer > 0:
            buffer_props = [
                (row[5] or 0) / total_buffer,  # forest
                (row[6] or 0) / total_buffer,  # wetland
                (row[7] or 0) / total_buffer,  # crop
                (row[8] or 0) / total_buffer   # other
            ]
            
            # Add to transitions - directly comparing proportions
            types = ['forest', 'wetland', 'crop', 'other']
            for i, from_type in enumerate(types):
                for j, to_type in enumerate(types):
                    if well_props[i] > 0:  # if we have this type in well
                        transitions[(from_type, to_type)].append(well_props[i] * buffer_props[j])

final_transitions = {k: sum(v) for k, v in transitions.items()}
```

```{python}
import plotly.graph_objects as go

# Create labels for nodes
labels = ['Wells Forest', 'Wells Wetland', 'Wells Crop', 'Wells Other',
          'Buffer Forest', 'Buffer Wetland', 'Buffer Crop', 'Buffer Other']

# Create source-target indices
source_indices = []
target_indices = []
values = []

# Map from land cover type to index
source_map = {'forest': 0, 'wetland': 1, 'crop': 2, 'other': 3}
target_map = {'forest': 4, 'wetland': 5, 'crop': 6, 'other': 7}

# Convert transitions to Sankey format
for (source, target), value in final_transitions.items():
    source_indices.append(source_map[source])
    target_indices.append(target_map[target])
    values.append(value)

# Create Sankey diagram
fig = go.Figure(data=[go.Sankey(
    node=dict(
        pad=15,
        thickness=20,
        line=dict(color="black", width=0.5),
        label=labels,
        color="blue"
    ),
    link=dict(
        source=source_indices,
        target=target_indices,
        value=values
    )
)])

# Update layout
fig.update_layout(
    title_text="Land Cover Transitions: Wells to Reference Buffers",
    font_size=10
)

fig.show()
```
